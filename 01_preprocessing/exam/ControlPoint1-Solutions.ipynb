{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control point: Data preprocessing\n",
    "#### M치ster en An치lisis de Datos, Ciberseguridad y Computaci칩n en la Nube\n",
    "#### Aprendizaje Autom치tico - Punto de Control 1 (31/10/2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name & Surnames: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset named Hoerchen (Hoerchen.csv) has more than 145K samples and more than 70 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of the control point is to preprocess the train data, designing a complete preprocessing scheme, and test it on test data. \n",
    "\n",
    "You must take into account that this is not a toy dataset, and its size could be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"automatic_scoring\" provides a way for comparing different schemes using a classifier, by means of 10-Fold CV and using AUC as metric. You will need to put the right seed as requested. Notice that the function just needs inputs (X) and target (y) arrays as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try anytime several options it is important to show the results of those discarded trials, because what is not visible cannot be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"automatic_testing\" trains the model on the train data and applies it to the test data. Do not change the classification algorithm, its parameters and the scoring choice. Those are fixed and their optimization is out of the scope of this control point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deliverable of this control point is this Jupyter Notebook containing the code, plus some short answers in markdown cells if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Keep in mind that some functions accept both Pandas dataframes and Numpy arrays, but some others only one of them. Nevertheless, we should know how to pass form one to the other and viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Keep in mind that some functions will take some time to run. You can continue working on other cells during the run to avoid wasting time waiting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (i) Split the data into 4 parts, i.e. train inputs and target (xtr, ytr) and test inputs and target (xte and yte), in such a way that the proportion of the classes is kept constant in train and test parts. The size of the training set must be 70% of the total size of the data, and the random seed to be used must be your ID card number (i.e. DNI without the letter). This random seed must be kept during all the control point in any possible place. [5%] <br>\n",
    "<br>\n",
    "* (ii) Checking for missing values and outliers. If any, treat the data however you consider better, arguing your decisions. [20%] <br>\n",
    "  <br>\n",
    "    - (a) Is there any missing value? If so, regarding the characteristics of the data, decide what to do arguing your answer. Modify your data according to your answer if necessary.  <br>\n",
    "      <br>\n",
    "    - (b) Is there any collective outlier? If so, regarding the characteristics of the data, decide what to do arguing your answer.  Modify your data according to your answer if necessary. <br>\n",
    "    <br>\n",
    "    - (c) From now on, this is your basic data. Therefore, it is save to overwrite the names of the data parts. <br>\n",
    "<br>\n",
    "\n",
    "* (iii) The feature selection method SelectPercentile (sklearn.feature_selection.SelectPercentile) uses different scores (f_classif, mutual_info_classif, chi2, f_regression, etc) in order to select the most relevant features. In the Scikit-Learn documentation\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile)\n",
    "you have the function info and an example of use of chi2 score. Use the feature selection method SelectPercentile with the mutual_info_classif score, and percentile parameter 20. [30%] <br>\n",
    "<br>\n",
    "    - (a) Which is the compression ratio you obtained? (Note: Compression ratio is the proportion of variables kept after the selection). <br>\n",
    "    <br>\n",
    "    - (b) Compare the performance with and without feature selection with the right scheme and function. Is selecting those variables a good idea? Argue your response. <br>\n",
    "    <br>\n",
    "    - (c) Regarding the answer to (b), get your current data in order to continue preprocessing.  <br>\n",
    "    <br>\n",
    "    \n",
    "* (iv) Check the balance of your current dataset. Which is its imbalance ratio? We can understand it both as the number of times the majority class is bigger than the minority class, or the proportion of the samples that are from minority class. If imbalance ratio is higher than 49 to 1 (equivalent to having less than 2% of minority class samples), discuss if it makes sense to apply imbalanced data treatments or not. Consider the size of the data and the performance you have obtained in (iii) (b) for the data you currently have. Act in consequence with total freedom on the sampling method to use if you need any. [20%] <br>\n",
    "<br>\n",
    "* (v) Apply principal component analysis to your data for compression, capturing at least 95% of the cumulative variance. How many extracted variables do you have? Which reduction percentage would you get if you apply it? Compare the performance with the one of your current non-compressed data. Would you use the pca compression here? Act consequently with your answer, and keep the data overwriting the names. [15%] <br> \n",
    "<br>\n",
    "* (vi) Once you are here, you have final preprocessed data using the definitive preprocessing scheme you have reasonably chosen. Check now the performance using the test data. Comment on the result you have obtained compared to the one in (v). [10%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "seed = 9425400# Your DNI number without letter and left zeros here, e.g. 09425400T => 9425400\n",
    "\n",
    "\n",
    "def automatic_scoring(X, y):\n",
    "    average_score = cross_val_score(estimator=RandomForestClassifier(n_estimators=100, random_state=seed), X=X, y=y, cv=5, scoring='roc_auc').mean()\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def automatic_testing(X_train, y_train, X_test, y_test):\n",
    "    auc_score = roc_auc_score(y_test, RandomForestClassifier(n_estimators=100, random_state=seed).fit(X_train, y_train).predict_proba(X_test)[:,1])\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tic-Toc\n",
    "def tic():\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "    \n",
    "def toc(verbose=True):\n",
    "    import time\n",
    "    gap = time.time() - startTime_for_tictoc\n",
    "    if verbose:\n",
    "        if 'startTime_for_tictoc' in globals():\n",
    "            print(\"Elapsed time is \" + str(gap) + \" seconds.\")\n",
    "        else:\n",
    "            print(\"Toc: start time not set\")\n",
    "    else:\n",
    "        return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('Hoerchen.csv')\n",
    "xtr, xte, ytr, yte = train_test_split(data.values[:,:-1], data.values[:,-1], test_size=0.3, random_state=seed, stratify=data.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.4621913580247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (ii)\n",
    "# We check for imbalance rate (only for information purposes)\n",
    "tic1=tic()\n",
    "imb_rate = (-sum([data.values[x, -1] for x in list(range(0, len(data.values[:, -1]))) if data.values[x, -1] == -1]))/sum([data.values[x, -1] for x in list(range(0, len(data.values[:, -1]))) if data.values[x, -1] == 1])\n",
    "imb_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "      <td>102024.000000</td>\n",
       "      <td>102025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>61.208536</td>\n",
       "      <td>26.490502</td>\n",
       "      <td>0.180773</td>\n",
       "      <td>1.667490</td>\n",
       "      <td>18.289738</td>\n",
       "      <td>1820.021907</td>\n",
       "      <td>-0.005729</td>\n",
       "      <td>0.200864</td>\n",
       "      <td>1.016555</td>\n",
       "      <td>-73.737062</td>\n",
       "      <td>...</td>\n",
       "      <td>1819.271988</td>\n",
       "      <td>0.024970</td>\n",
       "      <td>0.529898</td>\n",
       "      <td>0.278601</td>\n",
       "      <td>-64.647318</td>\n",
       "      <td>471.971560</td>\n",
       "      <td>0.473091</td>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.191212</td>\n",
       "      <td>-0.982220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>18.972717</td>\n",
       "      <td>4.494317</td>\n",
       "      <td>1.243443</td>\n",
       "      <td>31.875404</td>\n",
       "      <td>81.499202</td>\n",
       "      <td>1416.116244</td>\n",
       "      <td>1.028956</td>\n",
       "      <td>1.421043</td>\n",
       "      <td>20.647745</td>\n",
       "      <td>26.558552</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.947179</td>\n",
       "      <td>1.180713</td>\n",
       "      <td>1.647576</td>\n",
       "      <td>9.641195</td>\n",
       "      <td>36.719066</td>\n",
       "      <td>406.384807</td>\n",
       "      <td>1.073515</td>\n",
       "      <td>0.187366</td>\n",
       "      <td>0.499566</td>\n",
       "      <td>0.187734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-3.830000</td>\n",
       "      <td>-144.000000</td>\n",
       "      <td>-1039.000000</td>\n",
       "      <td>-562.300000</td>\n",
       "      <td>-6.120000</td>\n",
       "      <td>-2.860000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-1044.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-413.700000</td>\n",
       "      <td>-7.780000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>-311.000000</td>\n",
       "      <td>-420.300000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-1.910000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23.560000</td>\n",
       "      <td>-0.580000</td>\n",
       "      <td>-17.500000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>1014.800000</td>\n",
       "      <td>-0.660000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>860.900000</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-82.000000</td>\n",
       "      <td>174.600000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>62.460000</td>\n",
       "      <td>25.790000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1531.450000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-69.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1434.500000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>377.600000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>75.420000</td>\n",
       "      <td>28.570000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2299.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>-56.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2334.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>667.225000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.380000</td>\n",
       "      <td>954.500000</td>\n",
       "      <td>3380.000000</td>\n",
       "      <td>52817.900000</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>66.360000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64129.400000</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4197.900000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows 칑 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  102024.000000  102025.000000  102024.000000  102024.000000   \n",
       "mean       61.208536      26.490502       0.180773       1.667490   \n",
       "std        18.972717       4.494317       1.243443      31.875404   \n",
       "min         3.570000      12.000000      -3.830000    -144.000000   \n",
       "25%        48.000000      23.560000      -0.580000     -17.500000   \n",
       "50%        62.460000      25.790000       0.100000       1.000000   \n",
       "75%        75.420000      28.570000       0.820000      19.500000   \n",
       "max       100.000000     100.000000      50.380000     954.500000   \n",
       "\n",
       "                   4              5              6              7  \\\n",
       "count  102025.000000  102024.000000  102024.000000  102025.000000   \n",
       "mean       18.289738    1820.021907      -0.005729       0.200864   \n",
       "std        81.499202    1416.116244       1.028956       1.421043   \n",
       "min     -1039.000000    -562.300000      -6.120000      -2.860000   \n",
       "25%       -13.000000    1014.800000      -0.660000      -0.600000   \n",
       "50%        11.500000    1531.450000       0.040000       0.030000   \n",
       "75%        40.000000    2299.400000       0.700000       0.770000   \n",
       "max      3380.000000   52817.900000       5.760000      66.360000   \n",
       "\n",
       "                   8              9  ...             65             66  \\\n",
       "count  102025.000000  102024.000000  ...  102024.000000  102024.000000   \n",
       "mean        1.016555     -73.737062  ...    1819.271988       0.024970   \n",
       "std        20.647745      26.558552  ...    1700.947179       1.180713   \n",
       "min       -83.000000   -1044.000000  ...    -413.700000      -7.780000   \n",
       "25%        -9.500000     -86.000000  ...     860.900000      -0.720000   \n",
       "50%         0.500000     -69.500000  ...    1434.500000       0.080000   \n",
       "75%        10.500000     -56.500000  ...    2334.900000       0.830000   \n",
       "max       917.000000     -23.000000  ...   64129.400000       5.570000   \n",
       "\n",
       "                  67             68             69             70  \\\n",
       "count  102024.000000  102024.000000  102024.000000  102024.000000   \n",
       "mean        0.529898       0.278601     -64.647318     471.971560   \n",
       "std         1.647576       9.641195      36.719066     406.384807   \n",
       "min       -10.000000     -63.000000    -311.000000    -420.300000   \n",
       "25%        -0.550000      -5.000000     -82.000000     174.600000   \n",
       "50%         0.390000       0.000000     -55.000000     377.600000   \n",
       "75%         1.460000       5.000000     -38.000000     667.225000   \n",
       "max        15.560000     146.000000       0.000000    4197.900000   \n",
       "\n",
       "                  71             72             73             74  \n",
       "count  102024.000000  102025.000000  102024.000000  102025.000000  \n",
       "mean        0.473091       0.260587       0.191212      -0.982220  \n",
       "std         1.073515       0.187366       0.499566       0.187734  \n",
       "min       -20.000000      -0.550000      -1.910000      -1.000000  \n",
       "25%        -0.170000       0.140000      -0.100000      -1.000000  \n",
       "50%         0.560000       0.260000       0.280000      -1.000000  \n",
       "75%         1.210000       0.390000       0.580000      -1.000000  \n",
       "max         6.600000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (ii) (a)\n",
    "#Check for missing values in train\n",
    "df_tr = pd.DataFrame(xtr)\n",
    "df_tr = pd.concat([df_tr, pd.DataFrame(ytr, columns=[str(int(df_tr.columns[-1]) + 1)])], axis=1)\n",
    "df_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "      <td>101975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>61.209005</td>\n",
       "      <td>26.490635</td>\n",
       "      <td>0.180929</td>\n",
       "      <td>1.669782</td>\n",
       "      <td>18.290689</td>\n",
       "      <td>1820.090182</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>0.200944</td>\n",
       "      <td>1.016524</td>\n",
       "      <td>-73.739608</td>\n",
       "      <td>...</td>\n",
       "      <td>1819.315531</td>\n",
       "      <td>0.025117</td>\n",
       "      <td>0.529994</td>\n",
       "      <td>0.278696</td>\n",
       "      <td>-64.649649</td>\n",
       "      <td>471.994169</td>\n",
       "      <td>0.473037</td>\n",
       "      <td>0.260580</td>\n",
       "      <td>0.191183</td>\n",
       "      <td>-0.982211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>18.973114</td>\n",
       "      <td>4.494733</td>\n",
       "      <td>1.243541</td>\n",
       "      <td>31.876338</td>\n",
       "      <td>81.515264</td>\n",
       "      <td>1416.245310</td>\n",
       "      <td>1.028989</td>\n",
       "      <td>1.421225</td>\n",
       "      <td>20.650043</td>\n",
       "      <td>26.560722</td>\n",
       "      <td>...</td>\n",
       "      <td>1701.099294</td>\n",
       "      <td>1.180754</td>\n",
       "      <td>1.647679</td>\n",
       "      <td>9.642012</td>\n",
       "      <td>36.720379</td>\n",
       "      <td>406.411683</td>\n",
       "      <td>1.073562</td>\n",
       "      <td>0.187363</td>\n",
       "      <td>0.499540</td>\n",
       "      <td>0.187780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-3.830000</td>\n",
       "      <td>-144.000000</td>\n",
       "      <td>-1039.000000</td>\n",
       "      <td>-562.300000</td>\n",
       "      <td>-6.120000</td>\n",
       "      <td>-2.860000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-1044.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-413.700000</td>\n",
       "      <td>-7.780000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>-311.000000</td>\n",
       "      <td>-420.300000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-1.910000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23.560000</td>\n",
       "      <td>-0.580000</td>\n",
       "      <td>-17.500000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>1014.800000</td>\n",
       "      <td>-0.660000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>860.900000</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-82.000000</td>\n",
       "      <td>174.550000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>62.460000</td>\n",
       "      <td>25.790000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1531.600000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-69.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1434.500000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>377.600000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>75.420000</td>\n",
       "      <td>28.570000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2299.250000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>-56.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>667.250000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.380000</td>\n",
       "      <td>954.500000</td>\n",
       "      <td>3380.000000</td>\n",
       "      <td>52817.900000</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>66.360000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64129.400000</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4197.900000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows 칑 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  101975.000000  101975.000000  101975.000000  101975.000000   \n",
       "mean       61.209005      26.490635       0.180929       1.669782   \n",
       "std        18.973114       4.494733       1.243541      31.876338   \n",
       "min         3.570000      12.000000      -3.830000    -144.000000   \n",
       "25%        48.000000      23.560000      -0.580000     -17.500000   \n",
       "50%        62.460000      25.790000       0.100000       1.000000   \n",
       "75%        75.420000      28.570000       0.820000      19.500000   \n",
       "max       100.000000     100.000000      50.380000     954.500000   \n",
       "\n",
       "                   4              5              6              7  \\\n",
       "count  101975.000000  101975.000000  101975.000000  101975.000000   \n",
       "mean       18.290689    1820.090182      -0.005694       0.200944   \n",
       "std        81.515264    1416.245310       1.028989       1.421225   \n",
       "min     -1039.000000    -562.300000      -6.120000      -2.860000   \n",
       "25%       -13.000000    1014.800000      -0.660000      -0.600000   \n",
       "50%        11.500000    1531.600000       0.040000       0.030000   \n",
       "75%        40.000000    2299.250000       0.700000       0.770000   \n",
       "max      3380.000000   52817.900000       5.760000      66.360000   \n",
       "\n",
       "                   8              9  ...             65             66  \\\n",
       "count  101975.000000  101975.000000  ...  101975.000000  101975.000000   \n",
       "mean        1.016524     -73.739608  ...    1819.315531       0.025117   \n",
       "std        20.650043      26.560722  ...    1701.099294       1.180754   \n",
       "min       -83.000000   -1044.000000  ...    -413.700000      -7.780000   \n",
       "25%        -9.500000     -86.000000  ...     860.900000      -0.720000   \n",
       "50%         0.500000     -69.500000  ...    1434.500000       0.080000   \n",
       "75%        10.500000     -56.500000  ...    2335.000000       0.830000   \n",
       "max       917.000000     -23.000000  ...   64129.400000       5.570000   \n",
       "\n",
       "                  67             68             69             70  \\\n",
       "count  101975.000000  101975.000000  101975.000000  101975.000000   \n",
       "mean        0.529994       0.278696     -64.649649     471.994169   \n",
       "std         1.647679       9.642012      36.720379     406.411683   \n",
       "min       -10.000000     -63.000000    -311.000000    -420.300000   \n",
       "25%        -0.550000      -5.000000     -82.000000     174.550000   \n",
       "50%         0.390000       0.000000     -55.000000     377.600000   \n",
       "75%         1.460000       5.000000     -38.000000     667.250000   \n",
       "max        15.560000     146.000000       0.000000    4197.900000   \n",
       "\n",
       "                  71             72             73             74  \n",
       "count  101975.000000  101975.000000  101975.000000  101975.000000  \n",
       "mean        0.473037       0.260580       0.191183      -0.982211  \n",
       "std         1.073562       0.187363       0.499540       0.187780  \n",
       "min       -20.000000      -0.550000      -1.910000      -1.000000  \n",
       "25%        -0.170000       0.140000      -0.100000      -1.000000  \n",
       "50%         0.560000       0.260000       0.280000      -1.000000  \n",
       "75%         1.210000       0.390000       0.580000      -1.000000  \n",
       "max         6.600000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove them in train and get back numpy arrays\n",
    "df_tr.dropna(axis=0, how='any', inplace=True)\n",
    "xtr = df_tr.values[:, :-1]\n",
    "ytr = df_tr.values[:, -1]\n",
    "# Check\n",
    "df_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove them in test and get back numpy arrays\n",
    "df_te = pd.DataFrame(xte)\n",
    "df_te = pd.concat([df_te, pd.DataFrame(yte, columns=[str(int(df_te.columns[-1]) + 1)])], axis=1)\n",
    "df_te.dropna(axis=0, how='any', inplace=True)\n",
    "xte = df_te.values[:, :-1]\n",
    "yte = df_te.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 190.12281107902527 seconds.\n"
     ]
    }
   ],
   "source": [
    "# (ii) (b)\n",
    "# Check for outliers => Rule\n",
    "tic()\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "elip_env = EllipticEnvelope().fit(xtr)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: 10198\n",
      "From minority class: 526\n",
      "From majority class: 9672\n",
      "True\n",
      "Elapsed time is 1.6098523139953613 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in train\n",
    "tic()\n",
    "detection = elip_env.predict(xtr)\n",
    "outlier_positions_mah = [x for x in range(xtr.shape[0]) if detection[x] == -1]\n",
    "# Total amount of outliers in train\n",
    "print(\"Outliers: \" + str(len(outlier_positions_mah)))\n",
    "# Those from minority class (+1.0)\n",
    "print(\"From minority class: \" + str(sum(ytr[outlier_positions_mah] != -1)))\n",
    "# and majority class (-1.0)\n",
    "print(\"From majority class: \" + str(sum(ytr[outlier_positions_mah] == -1)))\n",
    "# Positions from majority class train outliers\n",
    "outlier_positions_mah_major = [x for x in range(xtr.shape[0]) if (detection[x] == -1 and ytr[x] == -1)]\n",
    "# Check\n",
    "print(len(outlier_positions_mah_major) == sum(ytr[outlier_positions_mah] == -1))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: 4409\n",
      "From minority class: 33\n",
      "From majority class: 4376\n",
      "True\n",
      "Elapsed time is 0.6803216934204102 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in test\n",
    "tic()\n",
    "detection_test = elip_env.predict(xte)\n",
    "outlier_positions_mah_test = [x for x in range(xte.shape[0]) if detection_test[x] == -1]\n",
    "# Total amount of outliers in train\n",
    "print(\"Outliers: \" + str(len(outlier_positions_mah_test)))\n",
    "# Those from minority class (+1.0)\n",
    "print(\"From minority class: \" + str(sum(ytr[outlier_positions_mah_test] != -1)))\n",
    "# and majority class (-1.0)\n",
    "print(\"From majority class: \" + str(sum(ytr[outlier_positions_mah_test] == -1)))\n",
    "# Positions from majority class train outliers\n",
    "outlier_positions_mah_major_test = [x for x in range(xte.shape[0]) if (detection_test[x] == -1 and yte[x] == -1)]\n",
    "# Check\n",
    "print(len(outlier_positions_mah_major_test) == sum(yte[outlier_positions_mah_test] == -1))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers deletion train\n",
    "df_tr = pd.DataFrame(xtr)\n",
    "df_tr = pd.concat([df_tr, pd.DataFrame(ytr, columns=[str(int(df_tr.columns[-1]) + 1)])], axis=1)\n",
    "df_tr.drop(df_tr.index[outlier_positions_mah_major], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers deletion test\n",
    "df_te = pd.DataFrame(xte)\n",
    "df_te = pd.concat([df_te, pd.DataFrame(yte, columns=[str(int(df_te.columns[-1]) + 1)])], axis=1)\n",
    "df_te.drop(df_te.index[outlier_positions_mah_major_test], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data modified overwritten\n",
    "xtr = df_tr.values[:, :-1]\n",
    "ytr = df_tr.values[:, -1]\n",
    "xte = df_te.values[:, :-1]\n",
    "yte = df_te.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92303, 74), (39521, 74), (92303,), (39521,)]\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print([xtr.shape, xte.shape, ytr.shape, yte.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 172.21773481369019 seconds.\n"
     ]
    }
   ],
   "source": [
    "# (iii)\n",
    "tic()\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_classif\n",
    "selperc = SelectPercentile(mutual_info_classif, percentile=20).fit(xtr, ytr)\n",
    "xtr_selperc = selperc.transform(xtr)\n",
    "xte_selperc = selperc.transform(xte)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92303, 15)\n",
      "(39521, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(xtr_selperc.shape)\n",
    "print(xte_selperc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972972972972973"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (iii) (a)\n",
    "reduction_rate = 1 - (xtr_selperc.shape[1]/xtr.shape[1])\n",
    "reduction_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Reduction is 79.73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: \n",
      "Elapsed time is 551.9796137809753 seconds.\n",
      "Reduced data: \n",
      "[0.9742921897252323, 0.9610601860395127]\n",
      "Elapsed time is 150.432599067688 seconds.\n"
     ]
    }
   ],
   "source": [
    "# (iii) (b)\n",
    "print(\"Original data: \")\n",
    "tic()\n",
    "auc = automatic_scoring(xtr, ytr)\n",
    "toc()\n",
    "print(\"Reduced data: \")\n",
    "tic()\n",
    "auc_selperc = automatic_scoring(xtr_selperc, ytr)\n",
    "print([auc, auc_selperc])\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Selecting those 15 variables instead of the original 74 makes sense, because the performance is really similar.\n",
    "In fact it is $auc = 0.978$ with the original 74 variables and $auc = 0.960$ with the selected subset of 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data modified overwritten\n",
    "xtr = xtr_selperc\n",
    "xte = xte_selperc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv)\n",
    "df_tr = pd.DataFrame(xtr)\n",
    "df_tr = pd.concat([df_tr, pd.DataFrame(ytr, columns=[str(int(df_tr.columns[-1]) + 1)])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.76736493936053"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_rate = (-sum([df_tr.values[x, -1] for x in list(range(0, len(df_tr.values[:, -1]))) if df_tr.values[x, -1] == -1]))/sum([df_tr.values[x, -1] for x in list(range(0, len(df_tr.values[:, -1]))) if df_tr.values[x, -1] == 1])\n",
    "imb_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009826332838585961"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prop = sum([df_tr.values[x, -1] for x in list(range(0, len(df_tr.values[:, -1]))) if df_tr.values[x, -1] == 1])/len(df_tr.values[:, -1])\n",
    "min_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imbalance is higher that 100 to 1, with a ratio below 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the huge amount of training samples (almost 100k), any pairwise distance matrix will be humongous. Moreover, distances will be always big because we are in a 15-D space. Besides, the performance is good ($auc = 0.960$). For all, I would not try to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v)\n",
    "# PCA auxiliar functions\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_projections_train(df, n_components=0.95):\n",
    "    pca = PCA(n_components)\n",
    "    X = df[df.columns[:-1]]  # Assuming the class in in the last column\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    proj_df = pd.DataFrame(data=X, columns=['PC' + str(x) for x in list(range(1, X.shape[1] + 1))])\n",
    "    proj_df = pd.concat([proj_df, df[df.columns[-1]]], axis=1)\n",
    "    return proj_df\n",
    "\n",
    "\n",
    "def pca_projections_test(df_train, df_test, n_components=0.95):\n",
    "    pca = PCA(n_components)\n",
    "    XTR = df_train[df_train.columns[:-1]]  # Assuming the class in in the last column\n",
    "    XTE = df_test[df_test.columns[:-1]]  # Assuming the class in in the last column\n",
    "    pca.fit(XTR)\n",
    "    XTE = pca.transform(XTE)\n",
    "    proj_df = pd.DataFrame(data=XTE, columns=['PC' + str(x) for x in list(range(1, XTE.shape[1] + 1))])\n",
    "    proj_df = pd.concat([proj_df, df_test[df_test.columns[-1]]], axis=1)\n",
    "    return proj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.DataFrame(xtr)\n",
    "df_tr = pd.concat([df_tr, pd.DataFrame(ytr, columns=[str(int(df_tr.columns[-1]) + 1)])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PC1           PC2           PC3           PC4           PC5  \\\n",
      "count  9.230300e+04  9.230300e+04  9.230300e+04  9.230300e+04  9.230300e+04   \n",
      "mean  -2.240716e-15  7.870371e-16 -3.645839e-16 -2.394059e-17 -4.955932e-16   \n",
      "std    7.458612e+01  4.030751e+01  2.643358e+01  2.524495e+01  1.591198e+01   \n",
      "min   -2.874108e+02 -1.100575e+02 -2.488094e+02 -1.059369e+02 -1.023504e+02   \n",
      "25%   -3.552112e+01 -2.565724e+01 -1.527327e+01 -1.583123e+01 -9.530237e+00   \n",
      "50%    1.872573e+00 -6.015692e+00  2.660715e+00 -8.142105e-01  1.294871e+00   \n",
      "75%    3.532206e+01  1.937319e+01  1.790973e+01  1.458722e+01  1.087128e+01   \n",
      "max    2.512953e+03  1.195989e+03  3.484352e+02  5.159453e+02  2.478668e+02   \n",
      "\n",
      "                 15  \n",
      "count  92303.000000  \n",
      "mean      -0.980347  \n",
      "std        0.197280  \n",
      "min       -1.000000  \n",
      "25%       -1.000000  \n",
      "50%       -1.000000  \n",
      "75%       -1.000000  \n",
      "max        1.000000  \n",
      "Elapsed time is 0.2902262210845947 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "df_tr = pca_projections_train(df_tr, n_components=0.95)\n",
    "print(df_tr.describe())\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr_pca = df_tr.values[:, :-1]\n",
    "ytr_pca = df_tr.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9112180560975179\n",
      "Elapsed time is 203.51836967468262 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "auc_pca = automatic_scoring(xtr_pca, ytr)\n",
    "print(auc_pca)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance using pca is much worse than not using it (AUC of 0.920 against 0.960). Therefore, considering the compresion is not that high (from 15 to 5 extracted variables), I would not use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to overwrite any name of the data parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92303, 15), (39521, 15), (92303,), (39521,)]\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print([xtr.shape, xte.shape, ytr.shape, yte.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vi)\n",
    "df_tr = pd.DataFrame(xtr)\n",
    "df_tr = pd.concat([df_tr, pd.DataFrame(ytr, columns=[str(int(df_tr.columns[-1]) + 1)])], axis=1)\n",
    "df_te = pd.DataFrame(xte)\n",
    "df_te = pd.concat([df_te, pd.DataFrame(yte, columns=[str(int(df_te.columns[-1]) + 1)])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553353070104559\n",
      "Elapsed time is 36.9154589176178 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "auc_test = automatic_testing(xtr, ytr, xte, yte)\n",
    "print(auc_test)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the original size and imbalance, the performance with the final preprocessing scheme in testing is good ($auc_{test} = 0.945$) and similar to the cross-validated training one ($auc_{train} = 0.960$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
